{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, avg, concat, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/31 08:40:16 WARN Utils: Your hostname, riyaz-Aspire-VX5-591G resolves to a loopback address: 127.0.1.1; using 192.168.1.164 instead (on interface enp3s0)\n",
      "23/08/31 08:40:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/31 08:40:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/31 08:40:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"FilterAddColumnRename\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the occupation dataset into a Spark DataFrame\n",
    "occupation = spark.read.csv(\"./occupation.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view to use Spark SQL\n",
    "\n",
    "occupation.createOrReplaceTempView(\"occupation_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional questions:\n",
    "\n",
    "Use both spark SQL and Pyspark to obtain answer wherever relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out rows where the age is greater than 30 and create a new DataFrame. Then, add a new column named \"is_elderly\" with a value of \"True\" for these rows and \"False\" otherwise.Rename the \"gender\" column to \"sex\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+-------------+--------+----------+\n",
      "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
      "+-------+---+---+-------------+--------+----------+\n",
      "|      2| 53|  F|        other|   94043|     false|\n",
      "|      5| 33|  F|        other|   15213|     false|\n",
      "|      6| 42|  M|    executive|   98101|     false|\n",
      "|      7| 57|  M|administrator|   91344|     false|\n",
      "|      8| 36|  M|administrator|   05201|     false|\n",
      "|     10| 53|  M|       lawyer|   90703|     false|\n",
      "|     11| 39|  F|        other|   30329|     false|\n",
      "|     13| 47|  M|     educator|   29206|     false|\n",
      "|     14| 45|  M|    scientist|   55106|     false|\n",
      "|     15| 49|  F|     educator|   97301|     false|\n",
      "|     18| 35|  F|        other|   37212|     false|\n",
      "|     19| 40|  M|    librarian|   02138|     false|\n",
      "|     20| 42|  F|    homemaker|   95660|     false|\n",
      "|     25| 39|  M|     engineer|   55107|     false|\n",
      "|     26| 49|  M|     engineer|   21044|     false|\n",
      "|     27| 40|  F|    librarian|   30030|     false|\n",
      "|     28| 32|  M|       writer|   55369|     false|\n",
      "|     29| 41|  M|   programmer|   94043|     false|\n",
      "|     34| 38|  F|administrator|   42141|     false|\n",
      "|     39| 41|  M|entertainment|   01040|     false|\n",
      "+-------+---+---+-------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark SQL\n",
    "\n",
    "# Assuming you have the \"occupation_view\" SQL view\n",
    "filtered_rows_sql = spark.sql(\"SELECT * FROM occupation_view WHERE age > 30\")\n",
    "\n",
    "# Add a new column \"is_elderly\" with a value of True or False\n",
    "filtered_rows_sql = filtered_rows_sql.withColumn(\"is_elderly\", when(col(\"age\") > 60, lit(True)).otherwise(lit(False)))\n",
    "\n",
    "# Rename the \"gender\" column to \"sex\"\n",
    "filtered_rows_sql = filtered_rows_sql.withColumnRenamed(\"gender\", \"sex\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "filtered_rows_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+-------------+--------+----------+\n",
      "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
      "+-------+---+---+-------------+--------+----------+\n",
      "|      2| 53|  F|        other|   94043|      true|\n",
      "|      5| 33|  F|        other|   15213|      true|\n",
      "|      6| 42|  M|    executive|   98101|      true|\n",
      "|      7| 57|  M|administrator|   91344|      true|\n",
      "|      8| 36|  M|administrator|   05201|      true|\n",
      "|     10| 53|  M|       lawyer|   90703|      true|\n",
      "|     11| 39|  F|        other|   30329|      true|\n",
      "|     13| 47|  M|     educator|   29206|      true|\n",
      "|     14| 45|  M|    scientist|   55106|      true|\n",
      "|     15| 49|  F|     educator|   97301|      true|\n",
      "|     18| 35|  F|        other|   37212|      true|\n",
      "|     19| 40|  M|    librarian|   02138|      true|\n",
      "|     20| 42|  F|    homemaker|   95660|      true|\n",
      "|     25| 39|  M|     engineer|   55107|      true|\n",
      "|     26| 49|  M|     engineer|   21044|      true|\n",
      "|     27| 40|  F|    librarian|   30030|      true|\n",
      "|     28| 32|  M|       writer|   55369|      true|\n",
      "|     29| 41|  M|   programmer|   94043|      true|\n",
      "|     34| 38|  F|administrator|   42141|      true|\n",
      "|     39| 41|  M|entertainment|   01040|      true|\n",
      "+-------+---+---+-------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pyspark\n",
    "\n",
    "# Assuming you have the \"occupation\" DataFrame\n",
    "filtered_occupation = occupation.filter(col(\"age\") > 30)\n",
    "\n",
    "# Add a new column \"is_elderly\" with a value of True or False\n",
    "filtered_occupation = filtered_occupation.withColumn(\"is_elderly\", when(col(\"age\") > 30, lit(True)).otherwise(lit(False)))\n",
    "\n",
    "# Rename the \"gender\" column to \"sex\"\n",
    "filtered_occupation = filtered_occupation.withColumnRenamed(\"gender\", \"sex\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "filtered_occupation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the average age of male and female users separately. Present the result in a new DataFrame with columns \"gender\" and \"avg_age\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|gender|           avg_age|\n",
      "+------+------------------+\n",
      "|     F| 33.81318681318681|\n",
      "|     M|34.149253731343286|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark SQL\n",
    "\n",
    "spark.sql(\"SELECT gender, AVG(age) AS avg_age FROM occupation_view GROUP BY gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|gender|           avg_age|\n",
      "+------+------------------+\n",
      "|     F| 33.81318681318681|\n",
      "|     M|34.149253731343286|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pyspark\n",
    "\n",
    "avg_age_df = occupation.groupBy(\"gender\").agg(avg(\"age\").alias(\"avg_age\"))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "avg_age_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a new column named \"full_name\" to the dataset by concatenating the \"user_id\" and \"occupation\" columns. Then, rename the \"zip_code\" column to \"postal_code\" in the same DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+-----------+---------------+\n",
      "|user_id|age|gender|   occupation|postal_code|      full_name|\n",
      "+-------+---+------+-------------+-----------+---------------+\n",
      "|      1| 24|     M|   technician|      85711|    1technician|\n",
      "|      2| 53|     F|        other|      94043|         2other|\n",
      "|      3| 23|     M|       writer|      32067|        3writer|\n",
      "|      4| 24|     M|   technician|      43537|    4technician|\n",
      "|      5| 33|     F|        other|      15213|         5other|\n",
      "|      6| 42|     M|    executive|      98101|     6executive|\n",
      "|      7| 57|     M|administrator|      91344| 7administrator|\n",
      "|      8| 36|     M|administrator|      05201| 8administrator|\n",
      "|      9| 29|     M|      student|      01002|       9student|\n",
      "|     10| 53|     M|       lawyer|      90703|       10lawyer|\n",
      "|     11| 39|     F|        other|      30329|        11other|\n",
      "|     12| 28|     F|        other|      06405|        12other|\n",
      "|     13| 47|     M|     educator|      29206|     13educator|\n",
      "|     14| 45|     M|    scientist|      55106|    14scientist|\n",
      "|     15| 49|     F|     educator|      97301|     15educator|\n",
      "|     16| 21|     M|entertainment|      10309|16entertainment|\n",
      "|     17| 30|     M|   programmer|      06355|   17programmer|\n",
      "|     18| 35|     F|        other|      37212|        18other|\n",
      "|     19| 40|     M|    librarian|      02138|    19librarian|\n",
      "|     20| 42|     F|    homemaker|      95660|    20homemaker|\n",
      "+-------+---+------+-------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark SQL\n",
    "\n",
    "spark.sql(\"SELECT *, CONCAT(user_id, occupation) AS full_name FROM occupation_view\") \\\n",
    "    .withColumnRenamed(\"zip_code\", \"postal_code\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+-----------+---------------+\n",
      "|user_id|age|gender|   occupation|postal_code|      full_name|\n",
      "+-------+---+------+-------------+-----------+---------------+\n",
      "|      1| 24|     M|   technician|      85711|    1technician|\n",
      "|      2| 53|     F|        other|      94043|         2other|\n",
      "|      3| 23|     M|       writer|      32067|        3writer|\n",
      "|      4| 24|     M|   technician|      43537|    4technician|\n",
      "|      5| 33|     F|        other|      15213|         5other|\n",
      "|      6| 42|     M|    executive|      98101|     6executive|\n",
      "|      7| 57|     M|administrator|      91344| 7administrator|\n",
      "|      8| 36|     M|administrator|      05201| 8administrator|\n",
      "|      9| 29|     M|      student|      01002|       9student|\n",
      "|     10| 53|     M|       lawyer|      90703|       10lawyer|\n",
      "|     11| 39|     F|        other|      30329|        11other|\n",
      "|     12| 28|     F|        other|      06405|        12other|\n",
      "|     13| 47|     M|     educator|      29206|     13educator|\n",
      "|     14| 45|     M|    scientist|      55106|    14scientist|\n",
      "|     15| 49|     F|     educator|      97301|     15educator|\n",
      "|     16| 21|     M|entertainment|      10309|16entertainment|\n",
      "|     17| 30|     M|   programmer|      06355|   17programmer|\n",
      "|     18| 35|     F|        other|      37212|        18other|\n",
      "|     19| 40|     M|    librarian|      02138|    19librarian|\n",
      "|     20| 42|     F|    homemaker|      95660|    20homemaker|\n",
      "+-------+---+------+-------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pyspark\n",
    "\n",
    "full_name_df = occupation.withColumn(\"full_name\", concat(col(\"user_id\"), col(\"occupation\"))) \\\n",
    "                         .withColumnRenamed(\"zip_code\", \"postal_code\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "full_name_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out rows where occupation is 'technician', select only the \"user_id\" and \"age\" columns, and then add a new column \"age_diff\" that calculates the difference between the user's age and the average age in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------------------+\n",
      "|user_id|age|          age_diff|\n",
      "+-------+---+------------------+\n",
      "|      1| 24|-10.05196182396607|\n",
      "|      4| 24|-10.05196182396607|\n",
      "|     44| 26| -8.05196182396607|\n",
      "|     77| 30| -4.05196182396607|\n",
      "|    143| 42|  7.94803817603393|\n",
      "|    197| 55| 20.94803817603393|\n",
      "|    244| 28| -6.05196182396607|\n",
      "|    294| 34| -0.05196182396607|\n",
      "|    311| 32| -2.05196182396607|\n",
      "|    325| 48| 13.94803817603393|\n",
      "|    441| 50| 15.94803817603393|\n",
      "|    456| 24|-10.05196182396607|\n",
      "|    458| 47| 12.94803817603393|\n",
      "|    488| 48| 13.94803817603393|\n",
      "|    545| 27| -7.05196182396607|\n",
      "|    670| 30| -4.05196182396607|\n",
      "|    715| 21|-13.05196182396607|\n",
      "|    717| 24|-10.05196182396607|\n",
      "|    718| 42|  7.94803817603393|\n",
      "|    738| 35|  0.94803817603393|\n",
      "+-------+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark SQL\n",
    "\n",
    "# Assuming you have the \"occupation\" DataFrame registered as a SQL view named \"occupation_view\"\n",
    "average_age = spark.sql(\"SELECT AVG(age) AS avg_age FROM occupation_view\").collect()[0][\"avg_age\"]\n",
    "\n",
    "spark.sql(\"SELECT user_id, age, age - {} AS age_diff FROM occupation_view WHERE occupation = 'technician'\"\n",
    "          .format(average_age)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------------+\n",
      "|user_id|age|           age_diff|\n",
      "+-------+---+-------------------+\n",
      "|      1| 24|-10.051961823966067|\n",
      "|      4| 24|-10.051961823966067|\n",
      "|     44| 26| -8.051961823966067|\n",
      "|     77| 30| -4.051961823966067|\n",
      "|    143| 42|  7.948038176033933|\n",
      "|    197| 55| 20.948038176033933|\n",
      "|    244| 28| -6.051961823966067|\n",
      "|    294| 34|-0.0519618239660673|\n",
      "|    311| 32|-2.0519618239660673|\n",
      "|    325| 48| 13.948038176033933|\n",
      "|    441| 50| 15.948038176033933|\n",
      "|    456| 24|-10.051961823966067|\n",
      "|    458| 47| 12.948038176033933|\n",
      "|    488| 48| 13.948038176033933|\n",
      "|    545| 27| -7.051961823966067|\n",
      "|    670| 30| -4.051961823966067|\n",
      "|    715| 21|-13.051961823966067|\n",
      "|    717| 24|-10.051961823966067|\n",
      "|    718| 42|  7.948038176033933|\n",
      "|    738| 35| 0.9480381760339327|\n",
      "+-------+---+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pyspark\n",
    "\n",
    "average_age = occupation.select(avg(\"age\")).collect()[0][0]\n",
    "\n",
    "age_diff_df = occupation.filter(col(\"occupation\") == \"technician\") \\\n",
    "                       .select(\"user_id\", \"age\") \\\n",
    "                       .withColumn(\"age_diff\", col(\"age\") - average_age)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "age_diff_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide the dataset into two DataFrames: one with male users and another with female users. Repartition both DataFrames to have 2 partitions each. Then, union these two DataFrames together and display the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+--------+\n",
      "|user_id|age|gender|occupation|zip_code|\n",
      "+-------+---+------+----------+--------+\n",
      "|    896| 28|     M|    writer|   91505|\n",
      "|    156| 25|     M|  educator|   08360|\n",
      "|    568| 39|     M|  educator|   01915|\n",
      "|    624| 19|     M|   student|   30067|\n",
      "|    832| 24|     M|technician|   77042|\n",
      "|    684| 28|     M|   student|   55414|\n",
      "|    905| 27|     M|     other|   30350|\n",
      "|    148| 33|     M|  engineer|   97006|\n",
      "|    313| 41|     M| marketing|   60035|\n",
      "|    478| 29|     M|     other|   10019|\n",
      "|    332| 20|     M|   student|   40504|\n",
      "|    492| 57|     M|  educator|   94618|\n",
      "|    833| 34|     M|    writer|   90019|\n",
      "|    470| 24|     M|programmer|   10021|\n",
      "|     21| 26|     M|    writer|   30068|\n",
      "|    265| 26|     M| executive|   84601|\n",
      "|     33| 23|     M|   student|   27510|\n",
      "|    133| 53|     M|  engineer|   78602|\n",
      "|    682| 23|     M|programmer|   55128|\n",
      "|    650| 42|     M|  engineer|   83814|\n",
      "+-------+---+------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Spark-SQL\n",
    "\n",
    "male_users = spark.sql(\"SELECT * FROM occupation_view WHERE gender = 'M'\").repartition(2)\n",
    "\n",
    "male_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|    505| 27|     F|        other|   20657|\n",
      "|    241| 26|     F|      student|   20001|\n",
      "|    629| 46|     F|        other|   44224|\n",
      "|    482| 18|     F|      student|   40256|\n",
      "|    304| 22|     F|      student|   71701|\n",
      "|    147| 40|     F|    librarian|   02143|\n",
      "|    354| 29|     F|    librarian|   48197|\n",
      "|    588| 18|     F|      student|   93063|\n",
      "|    175| 26|     F|    scientist|   21911|\n",
      "|    490| 29|     F|       artist|   V5A2B|\n",
      "|    457| 33|     F|     salesman|   30011|\n",
      "|    165| 20|     F|        other|   53715|\n",
      "|    342| 25|     F|        other|   98006|\n",
      "|    401| 46|     F|   healthcare|   84107|\n",
      "|    681| 44|     F|    marketing|   97208|\n",
      "|    238| 42|     F|administrator|   44124|\n",
      "|     52| 18|     F|      student|   55105|\n",
      "|    556| 35|     F|     educator|   30606|\n",
      "|    485| 44|     F|     educator|   95821|\n",
      "|    126| 28|     F|       lawyer|   20015|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "female_users = spark.sql(\"SELECT * FROM occupation_view WHERE gender = 'F'\").repartition(2)\n",
    "\n",
    "female_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+--------+\n",
      "|user_id|age|gender|occupation|zip_code|\n",
      "+-------+---+------+----------+--------+\n",
      "|    896| 28|     M|    writer|   91505|\n",
      "|    156| 25|     M|  educator|   08360|\n",
      "|    568| 39|     M|  educator|   01915|\n",
      "|    624| 19|     M|   student|   30067|\n",
      "|    832| 24|     M|technician|   77042|\n",
      "|    684| 28|     M|   student|   55414|\n",
      "|    905| 27|     M|     other|   30350|\n",
      "|    148| 33|     M|  engineer|   97006|\n",
      "|    313| 41|     M| marketing|   60035|\n",
      "|    478| 29|     M|     other|   10019|\n",
      "|    332| 20|     M|   student|   40504|\n",
      "|    492| 57|     M|  educator|   94618|\n",
      "|    833| 34|     M|    writer|   90019|\n",
      "|    470| 24|     M|programmer|   10021|\n",
      "|     21| 26|     M|    writer|   30068|\n",
      "|    265| 26|     M| executive|   84601|\n",
      "|     33| 23|     M|   student|   27510|\n",
      "|    133| 53|     M|  engineer|   78602|\n",
      "|    682| 23|     M|programmer|   55128|\n",
      "|    650| 42|     M|  engineer|   83814|\n",
      "+-------+---+------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = male_users.union(female_users)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|    505| 27|     F|        other|   20657|\n",
      "|    241| 26|     F|      student|   20001|\n",
      "|    629| 46|     F|        other|   44224|\n",
      "|    482| 18|     F|      student|   40256|\n",
      "|    304| 22|     F|      student|   71701|\n",
      "|    147| 40|     F|    librarian|   02143|\n",
      "|    354| 29|     F|    librarian|   48197|\n",
      "|    588| 18|     F|      student|   93063|\n",
      "|    175| 26|     F|    scientist|   21911|\n",
      "|    490| 29|     F|       artist|   V5A2B|\n",
      "|    457| 33|     F|     salesman|   30011|\n",
      "|    165| 20|     F|        other|   53715|\n",
      "|    342| 25|     F|        other|   98006|\n",
      "|    401| 46|     F|   healthcare|   84107|\n",
      "|    681| 44|     F|    marketing|   97208|\n",
      "|    238| 42|     F|administrator|   44124|\n",
      "|     52| 18|     F|      student|   55105|\n",
      "|    556| 35|     F|     educator|   30606|\n",
      "|    485| 44|     F|     educator|   95821|\n",
      "|    126| 28|     F|       lawyer|   20015|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using pySpark\n",
    "\n",
    "\n",
    "male_users = occupation.filter(col(\"gender\") == \"M\").repartition(2)\n",
    "female_users = occupation.filter(col(\"gender\") == \"F\").repartition(2)\n",
    "\n",
    "result_df = female_users.union(male_users)\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and fill a new DataFrame named user_ratings with columns user_id and rating max 10 column. Both user_data and user_ratings share the user_id column. Combine these two DataFrames to create a new DataFrame that includes user information and their corresponding ratings. Make sure to keep only the users present in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/31 08:50:55 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "[Stage 51:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|   name|rating|\n",
      "+-------+-------+------+\n",
      "|      1|   John|     9|\n",
      "|      2|  Alice|     8|\n",
      "|      3|    Bob|    10|\n",
      "|      4|    Eva|     7|\n",
      "|      5|  David|     9|\n",
      "|      6| Sophia|     6|\n",
      "|      7|Michael|    10|\n",
      "|      8| Olivia|     8|\n",
      "|      9|William|     7|\n",
      "|     10|   Emma|     9|\n",
      "+-------+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creating a Spark session\n",
    "spark = SparkSession.builder.appName(\"UserRatingsExample\").getOrCreate()\n",
    "\n",
    "#user_data DataFrame with user_id, name, age, and occupation columns\n",
    "user_data_data = [\n",
    "    (1, \"John\"),\n",
    "    (2, \"Alice\"),\n",
    "    (3, \"Bob\"),\n",
    "    (4, \"Eva\"),\n",
    "    (5, \"David\"),\n",
    "    (6, \"Sophia\"),\n",
    "    (7, \"Michael\"),\n",
    "    (8, \"Olivia\"),\n",
    "    (9, \"William\"),\n",
    "    (10, \"Emma\")\n",
    "]\n",
    "\n",
    "# Defining the schema for user_data DataFrame\n",
    "user_data_schema = [\"user_id\", \"name\"]\n",
    "\n",
    "# Create the user_data DataFrame\n",
    "user_data = spark.createDataFrame(user_data_data, user_data_schema)\n",
    "\n",
    "# user_ratings DataFrame with user_id and rating columns\n",
    "user_ratings_data = [\n",
    "    (1, 9),\n",
    "    (2, 8),\n",
    "    (3, 10),\n",
    "    (4, 7),\n",
    "    (5, 9),\n",
    "    (6, 6),\n",
    "    (7, 10),\n",
    "    (8, 8),\n",
    "    (9, 7),\n",
    "    (10, 9)\n",
    "]\n",
    "\n",
    "# Define the schema for user_ratings DataFrame\n",
    "user_ratings_schema = [\"user_id\", \"rating\"]\n",
    "\n",
    "# Create the user_ratings DataFrame\n",
    "user_ratings = spark.createDataFrame(user_ratings_data, user_ratings_schema)\n",
    "\n",
    "# Select relevant columns from \"user_ratings\"\n",
    "user_ratings_selected = user_ratings.select(\"user_id\", \"rating\")\n",
    "\n",
    "# Join \"user_data\" and \"user_ratings_selected\" on \"user_id\"\n",
    "combined_df = user_data.join(user_ratings_selected, on=\"user_id\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "combined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "| John|\n",
      "|Alice|\n",
      "+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2 = combined_df.select(\"name\")\n",
    "test2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|destination|\n",
      "+-----------+\n",
      "|       John|\n",
      "|      Alice|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test1 = combined_df.select(expr(\"name AS destination\"))\n",
    "test1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|rating|\n",
      "+------+\n",
      "|     9|\n",
      "|     8|\n",
      "|    10|\n",
      "|     7|\n",
      "|     9|\n",
      "|     6|\n",
      "|    10|\n",
      "|     8|\n",
      "|     7|\n",
      "|     9|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = combined_df.selectExpr(\"rating\")\n",
    "\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
