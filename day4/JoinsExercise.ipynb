{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/04 14:03:05 WARN Utils: Your hostname, riyaz-Aspire-VX5-591G resolves to a loopback address: 127.0.1.1; using 192.168.1.164 instead (on interface enp3s0)\n",
      "23/09/04 14:03:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/04 14:03:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"day3\").getOrCreate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question: You are given two DataFrames: employees_df and departments_df, which contain information about employees and their respective departments. The schema for the DataFrames is as follows:\n",
    "\n",
    "employees_df schema:\n",
    "|-- employee_id: integer (nullable = true)\n",
    "|-- employee_name: string (nullable = true)\n",
    "|-- department_id: integer (nullable = true)\n",
    "\n",
    "departments_df schema:\n",
    "\n",
    "|-- department_id: integer (nullable = true)\n",
    "|-- department_name: string (nullable = true)\n",
    "\n",
    "Employees DataFrame:\n",
    "                                                                                \n",
    "+-----------+-------------+-------------+\n",
    "|employee_id|employee_name|department_id|\n",
    "+-----------+-------------+-------------+\n",
    "|1          |Pallavi mam  |101          |\n",
    "|2          |Bob          |102          |\n",
    "|3          |Cathy        |101          |\n",
    "|4          |David        |103          |\n",
    "|5          |Amrit Sir    |104          |\n",
    "|6          |Alice        |null         |\n",
    "|7          |Eva          |null         |\n",
    "|8          |Frank        |110          |\n",
    "|9          |Grace        |109          |\n",
    "|10         |Henry        |null         |\n",
    "+-----------+-------------+-------------+\n",
    "\n",
    "\n",
    "\n",
    "Departments DataFrame:\n",
    "+-------------+------------------------+\n",
    "|department_id|department_name         |\n",
    "+-------------+------------------------+\n",
    "|101          |HR                      |\n",
    "|102          |Engineering             |\n",
    "|103          |Finance                 |\n",
    "|104          |Marketing               |\n",
    "|105          |Operations              |\n",
    "|106          |null                    |\n",
    "|107          |Operations              |\n",
    "|108          |Production              |\n",
    "|null         |Finance                 |\n",
    "|110          |Research and Development|\n",
    "+-------------+----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees DataFrame:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+\n",
      "|employee_id|employee_name|department_id|\n",
      "+-----------+-------------+-------------+\n",
      "|          1|  Pallavi mam|          101|\n",
      "|          2|          Bob|          102|\n",
      "|          3|        Cathy|          101|\n",
      "|          4|        David|          103|\n",
      "|          5|    Amrit Sir|          104|\n",
      "|          6|        Alice|         null|\n",
      "|          7|          Eva|         null|\n",
      "|          8|        Frank|          110|\n",
      "|          9|        Grace|          109|\n",
      "|         10|        Henry|         null|\n",
      "+-----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Create a SparkSession\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"CreateDataFrames\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# Create the Employees DataFrame\n",
    "employees_data = [\n",
    "    Row(employee_id=1, employee_name=\"Pallavi mam\", department_id=101),\n",
    "    Row(employee_id=2, employee_name=\"Bob\", department_id=102),\n",
    "    Row(employee_id=3, employee_name=\"Cathy\", department_id=101),\n",
    "    Row(employee_id=4, employee_name=\"David\", department_id=103),\n",
    "    Row(employee_id=5, employee_name=\"Amrit Sir\", department_id=104),\n",
    "    Row(employee_id=6, employee_name=\"Alice\", department_id=None),\n",
    "    Row(employee_id=7, employee_name=\"Eva\", department_id=None),\n",
    "    Row(employee_id=8, employee_name=\"Frank\", department_id=110),\n",
    "    Row(employee_id=9, employee_name=\"Grace\", department_id=109),\n",
    "    Row(employee_id=10, employee_name=\"Henry\", department_id=None)\n",
    "]\n",
    "\n",
    "employees_df = spark.createDataFrame(employees_data)\n",
    "\n",
    "# Show the Employees DataFrame\n",
    "print(\"Employees DataFrame:\")\n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departments DataFrame:\n",
      "+-------------+----------------+\n",
      "|department_id| department_name|\n",
      "+-------------+----------------+\n",
      "|          101|              HR|\n",
      "|          102|         Finance|\n",
      "|          103|       Marketing|\n",
      "|          104|              IT|\n",
      "|          105|           Sales|\n",
      "|          106|     Engineering|\n",
      "|          107|           Legal|\n",
      "|          108|      Operations|\n",
      "|          109|Customer Support|\n",
      "|          110|      Management|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the Departments DataFrame\n",
    "departments_data = [\n",
    "    Row(department_id=101, department_name=\"HR\"),\n",
    "    Row(department_id=102, department_name=\"Finance\"),\n",
    "    Row(department_id=103, department_name=\"Marketing\"),\n",
    "    Row(department_id=104, department_name=\"IT\"),\n",
    "    Row(department_id=105, department_name=\"Sales\"),\n",
    "    Row(department_id=106, department_name=\"Engineering\"),\n",
    "    Row(department_id=107, department_name=\"Legal\"),\n",
    "    Row(department_id=108, department_name=\"Operations\"),\n",
    "    Row(department_id=109, department_name=\"Customer Support\"),\n",
    "    Row(department_id=110, department_name=\"Management\")\n",
    "]\n",
    "\n",
    "departments_df = spark.createDataFrame(departments_data)\n",
    "\n",
    "# Show the Departments DataFrame\n",
    "print(\"Departments DataFrame:\")\n",
    "departments_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating temporary view for both DF\n",
    "\n",
    "departments_df.createOrReplaceTempView(\"department\")\n",
    "employees_df.createOrReplaceTempView(\"employee\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Expressions\n",
    "\n",
    "Question: How can you combine the employees_df and departments_df DataFrames based on the common \"department_id\" column to get a combined DataFrame with employee names and their respective department names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------+----------------+\n",
      "|department_id|employee_id|employee_name| department_name|\n",
      "+-------------+-----------+-------------+----------------+\n",
      "|          101|          1|  Pallavi mam|              HR|\n",
      "|          101|          3|        Cathy|              HR|\n",
      "|          102|          2|          Bob|         Finance|\n",
      "|          103|          4|        David|       Marketing|\n",
      "|          104|          5|    Amrit Sir|              IT|\n",
      "|          109|          9|        Grace|Customer Support|\n",
      "|          110|          8|        Frank|      Management|\n",
      "+-------------+-----------+-------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinExpression = departments_df['department_id'] == employees_df['department_id']\n",
    "\n",
    "departments_df.join(employees_df, joinExpression).select(departments_df['department_id'],employees_df['employee_id'],employees_df['employee_name'],departments_df['department_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                             (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------+----------------+\n",
      "|department_id|employee_id|employee_name| department_name|\n",
      "+-------------+-----------+-------------+----------------+\n",
      "|          101|          1|  Pallavi mam|              HR|\n",
      "|          101|          3|        Cathy|              HR|\n",
      "|          102|          2|          Bob|         Finance|\n",
      "|          103|          4|        David|       Marketing|\n",
      "|          104|          5|    Amrit Sir|              IT|\n",
      "|          109|          9|        Grace|Customer Support|\n",
      "|          110|          8|        Frank|      Management|\n",
      "+-------------+-----------+-------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "join_exp = spark.sql(\"\"\"\n",
    "                    select d.department_id, e.employee_id, e.employee_name, d.department_name\n",
    "                    from department d\n",
    "                    join employee e\n",
    "                    on d.department_id = e.department_id\n",
    "\"\"\")\n",
    "                     \n",
    "join_exp.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Joins\n",
    "\n",
    "Question: How can you retrieve employee names and their respective department names for employees belonging to the \"Engineering\" department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|employee_name|department_name|\n",
      "+-------------+---------------+\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinExpression = departments_df['department_id'] == employees_df['department_id']\n",
    "engg_exp = departments_df['department_name'] == 'Engineering'\n",
    "\n",
    "departments_df.join(employees_df, joinExpression).select(employees_df['employee_name'],departments_df['department_name']).where(engg_exp).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|employee_name|department_name|\n",
      "+-------------+---------------+\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "inner_join_sql = spark.sql(\"\"\"\n",
    "                            select e.employee_name, d.department_name\n",
    "                           from department d\n",
    "                           join employee e\n",
    "                           on e.department_id = d.department_id\n",
    "                           where d.department_name = 'Engineering' \n",
    " \"\"\")\n",
    "\n",
    "inner_join_sql.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Joins\n",
    "\n",
    "Question: Retrieve a DataFrame that contains all employees along with their department names. If an employee doesn't have a department assigned, display \"No Department\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|employee_name| department_name|\n",
      "+-------------+----------------+\n",
      "|        Alice|   No Department|\n",
      "|          Eva|   No Department|\n",
      "|        Henry|   No Department|\n",
      "|        Cathy|              HR|\n",
      "|  Pallavi mam|              HR|\n",
      "|          Bob|         Finance|\n",
      "|        David|       Marketing|\n",
      "|    Amrit Sir|              IT|\n",
      "|No Department|           Sales|\n",
      "|No Department|     Engineering|\n",
      "|No Department|           Legal|\n",
      "|No Department|      Operations|\n",
      "|        Grace|Customer Support|\n",
      "|        Frank|      Management|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinType = 'outer'\n",
    "\n",
    "#Outer joined two dataframes which returned every value possible and null if any value is not present\n",
    "outer_joined_df = departments_df.join(employees_df, joinExpression, joinType).select(employees_df['employee_name'],departments_df['department_name'])\n",
    "\n",
    "#filled null with default value as No Department\n",
    "No_dept_filled = outer_joined_df.na.fill('No Department')\n",
    "No_dept_filled.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|employee_name| department_name|\n",
      "+-------------+----------------+\n",
      "|        Alice|   no department|\n",
      "|          Eva|   no department|\n",
      "|        Henry|   no department|\n",
      "|        Cathy|              HR|\n",
      "|  Pallavi mam|              HR|\n",
      "|          Bob|         Finance|\n",
      "|        David|       Marketing|\n",
      "|    Amrit Sir|              IT|\n",
      "|  no Employee|           Sales|\n",
      "|  no Employee|     Engineering|\n",
      "|  no Employee|           Legal|\n",
      "|  no Employee|      Operations|\n",
      "|        Grace|Customer Support|\n",
      "|        Frank|      Management|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "outer_join_sql = spark.sql(\"\"\"\n",
    "                            select coalesce(e.employee_name, 'no Employee') as employee_name, \n",
    "                                   coalesce(d.department_name, 'no department') as department_name\n",
    "                           from employee e\n",
    "                           full outer join department d\n",
    "                           on d.department_id = e.department_id\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "outer_join_sql.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Outer Joins\n",
    "\n",
    "Question: List all employees along with their department names. If an employee doesn't have a department assigned, display \"No Department\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|employee_name| department_name|\n",
      "+-------------+----------------+\n",
      "|  Pallavi mam|              HR|\n",
      "|          Bob|         Finance|\n",
      "|        David|       Marketing|\n",
      "|        Cathy|              HR|\n",
      "|        Alice|   no Department|\n",
      "|    Amrit Sir|              IT|\n",
      "|        Frank|      Management|\n",
      "|          Eva|   no Department|\n",
      "|        Henry|   no Department|\n",
      "|        Grace|Customer Support|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinType = 'left_outer'\n",
    "employees_df.join(departments_df,joinExpression,joinType).select(employees_df['employee_name'],departments_df['department_name']).na.fill('no Department').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|employee_name| department_name|\n",
      "+-------------+----------------+\n",
      "|  Pallavi mam|              HR|\n",
      "|          Bob|         Finance|\n",
      "|        David|       Marketing|\n",
      "|        Cathy|              HR|\n",
      "|        Alice|   no department|\n",
      "|    Amrit Sir|              IT|\n",
      "|        Frank|      Management|\n",
      "|          Eva|   no department|\n",
      "|        Henry|   no department|\n",
      "|        Grace|Customer Support|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "left_outer_join_sql = spark.sql(\"\"\"\n",
    "                                    select e.employee_name,\n",
    "                                            coalesce(d.department_name, 'no department') as department_name\n",
    "                                    from employee e\n",
    "                                    left outer join department d\n",
    "                                    on e.department_id = d.department_id       \n",
    "\n",
    "                                \"\"\")\n",
    "\n",
    "left_outer_join_sql.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Outer Joins\n",
    "\n",
    "Question: Display a list of departments along with employee names. If a department has no employees, display \"No Employees\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "| department_name|employee_name|\n",
      "+----------------+-------------+\n",
      "|              HR|        Cathy|\n",
      "|              HR|  Pallavi mam|\n",
      "|         Finance|          Bob|\n",
      "|       Marketing|        David|\n",
      "|              IT|    Amrit Sir|\n",
      "|     Engineering|  No Employee|\n",
      "|           Sales|  No Employee|\n",
      "|      Management|        Frank|\n",
      "|           Legal|  No Employee|\n",
      "|      Operations|  No Employee|\n",
      "|Customer Support|        Grace|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinType = 'right_outer'\n",
    "\n",
    "employees_df.join(departments_df,joinExpression,joinType).select(departments_df['department_name'],employees_df['employee_name']).na.fill('No Employee', subset=['employee_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "| department_name|employee_name|\n",
      "+----------------+-------------+\n",
      "|              HR|        Cathy|\n",
      "|              HR|  Pallavi mam|\n",
      "|         Finance|          Bob|\n",
      "|       Marketing|        David|\n",
      "|              IT|    Amrit Sir|\n",
      "|     Engineering|  No employee|\n",
      "|           Sales|  No employee|\n",
      "|      Management|        Frank|\n",
      "|           Legal|  No employee|\n",
      "|      Operations|  No employee|\n",
      "|Customer Support|        Grace|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "right_outer_join_sql = spark.sql(\"\"\"\n",
    "                                select d.department_name as department_name,\n",
    "                                       coalesce(e.employee_name,'No employee') as employee_name\n",
    "                                 from employee e\n",
    "                                 right outer join department d\n",
    "                                 on e.department_id = d.department_id\n",
    "                                \"\"\")\n",
    "\n",
    "right_outer_join_sql.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Semi Joins\n",
    "\n",
    "Question: Retrieve a DataFrame that includes employee names for departments that have employees.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|employee_name|\n",
      "+-------------+\n",
      "|  Pallavi mam|\n",
      "|        Cathy|\n",
      "|          Bob|\n",
      "|        David|\n",
      "|    Amrit Sir|\n",
      "|        Grace|\n",
      "|        Frank|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinType = 'left_semi'\n",
    "\n",
    "employees_df.join(departments_df,joinExpression,joinType).select(employees_df['employee_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|employee_name|\n",
      "+-------------+\n",
      "|  Pallavi mam|\n",
      "|        Cathy|\n",
      "|          Bob|\n",
      "|        David|\n",
      "|    Amrit Sir|\n",
      "|        Grace|\n",
      "|        Frank|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "left_semi_join_sql = spark.sql(\"\"\"\n",
    "                                select e.employee_name\n",
    "                               from employee e\n",
    "                               left semi join department d\n",
    "                               on e.department_id = d.department_id\n",
    "                                \n",
    "                               \"\"\" )\n",
    "\n",
    "left_semi_join_sql.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Anti Joins\n",
    "\n",
    "Question: Find the employees who don't belong to any department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|employee_name|\n",
      "+-------------+\n",
      "|        Alice|\n",
      "|          Eva|\n",
      "|        Henry|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinType = 'left_anti'\n",
    "\n",
    "employees_df.join(departments_df,joinExpression,joinType).select(employees_df['employee_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|employee_name|\n",
      "+-------------+\n",
      "|        Alice|\n",
      "|          Eva|\n",
      "|        Henry|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "left_anti_join_sql = spark.sql(\"\"\"\n",
    "                                select e.employee_name\n",
    "                               from employee e\n",
    "                               left anti join department d\n",
    "                               on e.department_id = d.department_id\n",
    "                                \n",
    "                               \"\"\" )\n",
    "\n",
    "left_anti_join_sql.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross (Cartesian) Joins\n",
    "\n",
    "Question: Create a DataFrame that contains all possible combinations of employees and departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+-------------+----------------+\n",
      "|employee_id|employee_name|department_id|department_id| department_name|\n",
      "+-----------+-------------+-------------+-------------+----------------+\n",
      "|          1|  Pallavi mam|          101|          101|              HR|\n",
      "|          1|  Pallavi mam|          101|          102|         Finance|\n",
      "|          2|          Bob|          102|          101|              HR|\n",
      "|          2|          Bob|          102|          102|         Finance|\n",
      "|          1|  Pallavi mam|          101|          103|       Marketing|\n",
      "|          1|  Pallavi mam|          101|          104|              IT|\n",
      "|          2|          Bob|          102|          103|       Marketing|\n",
      "|          2|          Bob|          102|          104|              IT|\n",
      "|          1|  Pallavi mam|          101|          105|           Sales|\n",
      "|          1|  Pallavi mam|          101|          106|     Engineering|\n",
      "|          2|          Bob|          102|          105|           Sales|\n",
      "|          2|          Bob|          102|          106|     Engineering|\n",
      "|          1|  Pallavi mam|          101|          107|           Legal|\n",
      "|          1|  Pallavi mam|          101|          108|      Operations|\n",
      "|          1|  Pallavi mam|          101|          109|Customer Support|\n",
      "|          1|  Pallavi mam|          101|          110|      Management|\n",
      "|          2|          Bob|          102|          107|           Legal|\n",
      "|          2|          Bob|          102|          108|      Operations|\n",
      "|          2|          Bob|          102|          109|Customer Support|\n",
      "|          2|          Bob|          102|          110|      Management|\n",
      "+-----------+-------------+-------------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "\n",
    "joinType = 'cross'\n",
    "employees_df.crossJoin(departments_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+-------------+----------------+\n",
      "|employee_id|employee_name|department_id|department_id| department_name|\n",
      "+-----------+-------------+-------------+-------------+----------------+\n",
      "|          1|  Pallavi mam|          101|          101|              HR|\n",
      "|          1|  Pallavi mam|          101|          102|         Finance|\n",
      "|          2|          Bob|          102|          101|              HR|\n",
      "|          2|          Bob|          102|          102|         Finance|\n",
      "|          1|  Pallavi mam|          101|          103|       Marketing|\n",
      "|          1|  Pallavi mam|          101|          104|              IT|\n",
      "|          2|          Bob|          102|          103|       Marketing|\n",
      "|          2|          Bob|          102|          104|              IT|\n",
      "|          1|  Pallavi mam|          101|          105|           Sales|\n",
      "|          1|  Pallavi mam|          101|          106|     Engineering|\n",
      "|          2|          Bob|          102|          105|           Sales|\n",
      "|          2|          Bob|          102|          106|     Engineering|\n",
      "|          1|  Pallavi mam|          101|          107|           Legal|\n",
      "|          1|  Pallavi mam|          101|          108|      Operations|\n",
      "|          1|  Pallavi mam|          101|          109|Customer Support|\n",
      "|          1|  Pallavi mam|          101|          110|      Management|\n",
      "|          2|          Bob|          102|          107|           Legal|\n",
      "|          2|          Bob|          102|          108|      Operations|\n",
      "|          2|          Bob|          102|          109|Customer Support|\n",
      "|          2|          Bob|          102|          110|      Management|\n",
      "+-----------+-------------+-------------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sparksql\n",
    "\n",
    "cross_join_sql = spark.sql(\"\"\"\n",
    "                            select * \n",
    "                           from employee\n",
    "                           cross join department\n",
    "\"\"\")\n",
    "                           \n",
    "cross_join_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
